{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "\n",
    "# Nitish Kumar Reddy Vinta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will focus on healthcare. This data set is made available by MIT. It contains data about 9,026 heartbeat measurements. Each row represents a single measurement (captured on a timeline). There are a total of 80 data points (columns). This is a multiclass classification task: predict whether the measurement represents a normal heartbeat or other anomalies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Variables\n",
    "\n",
    "You will use the **hearbeat_cleaned.csv** data set for this assignment. Each row represents a single measurement. Columns labeled as T1 from T80 are the time steps on the timeline (there are 80 time steps, each time step has only one measurement). \n",
    "\n",
    "The last column is the target variable. It shows the label (category) of the measurement as follows:<br>\n",
    "0 = Normal<br>\n",
    "1 = Supraventricular premature beat<br>\n",
    "2 = Premature ventricular contraction<br>\n",
    "3 = Fusion of ventricular and normal beat<br>\n",
    "4 = Unclassifiable beat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Use the data set **hearbeat_cleaned.csv** to predict the column called **Target**. The input variables are columns labeled as **T1 to T80**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission:\n",
    "\n",
    "Please save and submit this Jupyter notebook file. The correctness of the code matters for your grade. **Readability and organization of your code is also important.** You may lose points for submitting unreadable/undecipherable code. Therefore, use markdown cells to create sections, and use comments where necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "\n",
    "The data is cleaned up. There are no unqueal length sequences. And, there is no zero padding. So, you shouldn't use any `Masking` layer (like I mentioned in the lecture). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Prepare the Data (1 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert as many cells as you need for data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Nitish Reddy\\\\Downloads'"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"heartbeat_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7960, 81)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "      <th>...</th>\n",
       "      <th>T72</th>\n",
       "      <th>T73</th>\n",
       "      <th>T74</th>\n",
       "      <th>T75</th>\n",
       "      <th>T76</th>\n",
       "      <th>T77</th>\n",
       "      <th>T78</th>\n",
       "      <th>T79</th>\n",
       "      <th>T80</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.987</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.1620</td>\n",
       "      <td>0.1470</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.1960</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.1990</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.2080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>0.0703</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.1910</td>\n",
       "      <td>0.1520</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.2110</td>\n",
       "      <td>0.2070</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0961</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2260</td>\n",
       "      <td>0.2420</td>\n",
       "      <td>0.2440</td>\n",
       "      <td>0.2860</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.8160</td>\n",
       "      <td>0.9770</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0722</td>\n",
       "      <td>0.0567</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0851</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>0.0593</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.8690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4210</td>\n",
       "      <td>0.8030</td>\n",
       "      <td>0.9510</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.0628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T1     T2     T3      T4      T5      T6      T7      T8      T9  \\\n",
       "0  0.987  0.892  0.461  0.1130  0.1490  0.1900  0.1650  0.1620  0.1470   \n",
       "1  1.000  0.918  0.621  0.1330  0.1050  0.1250  0.1170  0.0898  0.0703   \n",
       "2  1.000  0.751  0.143  0.1040  0.0961  0.0519  0.0442  0.0416  0.0364   \n",
       "3  1.000  0.740  0.235  0.0464  0.0722  0.0567  0.0103  0.0155  0.0284   \n",
       "4  1.000  0.833  0.309  0.0191  0.1010  0.1200  0.1040  0.0874  0.0765   \n",
       "\n",
       "      T10  ...     T72     T73     T74     T75    T76     T77     T78    T79  \\\n",
       "0  0.1380  ...  0.1970  0.1970  0.1960  0.2030  0.201  0.1990  0.2010  0.205   \n",
       "1  0.0781  ...  0.1950  0.1910  0.1520  0.1720  0.207  0.2110  0.2070  0.207   \n",
       "2  0.0857  ...  0.2260  0.2420  0.2440  0.2860  0.468  0.8160  0.9770  0.452   \n",
       "3  0.0155  ...  0.0851  0.0747  0.0515  0.0593  0.067  0.0361  0.1210  0.451   \n",
       "4  0.0765  ...  0.2050  0.4210  0.8030  0.9510  0.467  0.0000  0.0519  0.082   \n",
       "\n",
       "      T80  Target  \n",
       "0  0.2080       0  \n",
       "1  0.1720       0  \n",
       "2  0.0519       0  \n",
       "3  0.8690       0  \n",
       "4  0.0628       0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Target']\n",
    "x = data.drop('Target',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "      <th>...</th>\n",
       "      <th>T72</th>\n",
       "      <th>T73</th>\n",
       "      <th>T74</th>\n",
       "      <th>T75</th>\n",
       "      <th>T76</th>\n",
       "      <th>T77</th>\n",
       "      <th>T78</th>\n",
       "      <th>T79</th>\n",
       "      <th>T80</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.987</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.1620</td>\n",
       "      <td>0.1470</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.1960</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.1990</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.2080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>0.0703</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.1910</td>\n",
       "      <td>0.1520</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.2110</td>\n",
       "      <td>0.2070</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0961</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2260</td>\n",
       "      <td>0.2420</td>\n",
       "      <td>0.2440</td>\n",
       "      <td>0.2860</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.8160</td>\n",
       "      <td>0.9770</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0722</td>\n",
       "      <td>0.0567</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0851</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>0.0593</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.8690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4210</td>\n",
       "      <td>0.8030</td>\n",
       "      <td>0.9510</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.0628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T1     T2     T3      T4      T5      T6      T7      T8      T9  \\\n",
       "0  0.987  0.892  0.461  0.1130  0.1490  0.1900  0.1650  0.1620  0.1470   \n",
       "1  1.000  0.918  0.621  0.1330  0.1050  0.1250  0.1170  0.0898  0.0703   \n",
       "2  1.000  0.751  0.143  0.1040  0.0961  0.0519  0.0442  0.0416  0.0364   \n",
       "3  1.000  0.740  0.235  0.0464  0.0722  0.0567  0.0103  0.0155  0.0284   \n",
       "4  1.000  0.833  0.309  0.0191  0.1010  0.1200  0.1040  0.0874  0.0765   \n",
       "\n",
       "      T10  ...     T72     T73     T74     T75    T76     T77     T78    T79  \\\n",
       "0  0.1380  ...  0.1970  0.1970  0.1960  0.2030  0.201  0.1990  0.2010  0.205   \n",
       "1  0.0781  ...  0.1950  0.1910  0.1520  0.1720  0.207  0.2110  0.2070  0.207   \n",
       "2  0.0857  ...  0.2260  0.2420  0.2440  0.2860  0.468  0.8160  0.9770  0.452   \n",
       "3  0.0155  ...  0.0851  0.0747  0.0515  0.0593  0.067  0.0361  0.1210  0.451   \n",
       "4  0.0765  ...  0.2050  0.4210  0.8030  0.9510  0.467  0.0000  0.0519  0.082   \n",
       "\n",
       "      T80  Target  \n",
       "0  0.2080       0  \n",
       "1  0.1720       0  \n",
       "2  0.0519       0  \n",
       "3  0.8690       0  \n",
       "4  0.0628       0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target variables need to be an array with integer type\n",
    "train_y = np.array(train_y)\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "train_y = train_y.astype(np.int32)\n",
    "test_y = test_y.astype(np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 4, 0, 0, 0])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the first 10 values of the train_y data set\n",
    "train_y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x= np.array(train_x)\n",
    "test_x= np.array(test_x)\n",
    "\n",
    "train_x = train_x.astype(np.float32)\n",
    "test_x = test_x.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.968 ],\n",
       "        [0.825 ],\n",
       "        [0.13  ],\n",
       "        ...,\n",
       "        [0.    ],\n",
       "        [0.0345],\n",
       "        [0.188 ]],\n",
       "\n",
       "       [[1.    ],\n",
       "        [0.922 ],\n",
       "        [0.746 ],\n",
       "        ...,\n",
       "        [0.0216],\n",
       "        [0.0302],\n",
       "        [0.0474]],\n",
       "\n",
       "       [[0.784 ],\n",
       "        [0.637 ],\n",
       "        [0.327 ],\n",
       "        ...,\n",
       "        [0.322 ],\n",
       "        [0.322 ],\n",
       "        [0.316 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.862 ],\n",
       "        [0.941 ],\n",
       "        [0.544 ],\n",
       "        ...,\n",
       "        [0.586 ],\n",
       "        [0.568 ],\n",
       "        [0.595 ]],\n",
       "\n",
       "       [[1.    ],\n",
       "        [0.905 ],\n",
       "        [0.312 ],\n",
       "        ...,\n",
       "        [0.32  ],\n",
       "        [0.319 ],\n",
       "        [0.314 ]],\n",
       "\n",
       "       [[1.    ],\n",
       "        [0.735 ],\n",
       "        [0.146 ],\n",
       "        ...,\n",
       "        [0.881 ],\n",
       "        [0.84  ],\n",
       "        [0.816 ]]], dtype=float32)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], 1))\n",
    "test_x = np.reshape(test_x, (test_x.shape[0], test_x.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5572, 80, 1), (5572,))"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.968 ],\n",
       "        [0.825 ],\n",
       "        [0.13  ],\n",
       "        ...,\n",
       "        [0.    ],\n",
       "        [0.0345],\n",
       "        [0.188 ]],\n",
       "\n",
       "       [[1.    ],\n",
       "        [0.922 ],\n",
       "        [0.746 ],\n",
       "        ...,\n",
       "        [0.0216],\n",
       "        [0.0302],\n",
       "        [0.0474]],\n",
       "\n",
       "       [[0.784 ],\n",
       "        [0.637 ],\n",
       "        [0.327 ],\n",
       "        ...,\n",
       "        [0.322 ],\n",
       "        [0.322 ],\n",
       "        [0.316 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.862 ],\n",
       "        [0.941 ],\n",
       "        [0.544 ],\n",
       "        ...,\n",
       "        [0.586 ],\n",
       "        [0.568 ],\n",
       "        [0.595 ]],\n",
       "\n",
       "       [[1.    ],\n",
       "        [0.905 ],\n",
       "        [0.312 ],\n",
       "        ...,\n",
       "        [0.32  ],\n",
       "        [0.319 ],\n",
       "        [0.314 ]],\n",
       "\n",
       "       [[1.    ],\n",
       "        [0.735 ],\n",
       "        [0.146 ],\n",
       "        ...,\n",
       "        [0.881 ],\n",
       "        [0.84  ],\n",
       "        [0.816 ]]], dtype=float32)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the baseline (0.5 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.582035\n",
       "4    0.198995\n",
       "2    0.155402\n",
       "1    0.055905\n",
       "3    0.007663\n",
       "Name: Target, dtype: float64"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Target'].value_counts()/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a cross-sectional shallow model using Keras (with only one hidden layer) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.Flatten(input_shape=[80, 1]),\n",
    "    keras.layers.Dense(5, activation='relu'),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.8711 - accuracy: 0.7148 - val_loss: 0.7795 - val_accuracy: 0.7161\n",
      "Epoch 2/25\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.6618 - accuracy: 0.7872 - val_loss: 0.8024 - val_accuracy: 0.7638\n",
      "Epoch 3/25\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.6102 - accuracy: 0.7922 - val_loss: 0.6318 - val_accuracy: 0.7919\n",
      "Epoch 4/25\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.7979 - val_loss: 0.7028 - val_accuracy: 0.7534\n",
      "Epoch 5/25\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.8067 - val_loss: 0.6435 - val_accuracy: 0.7722\n",
      "Epoch 6/25\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.8160 - val_loss: 0.5734 - val_accuracy: 0.7965\n",
      "Epoch 7/25\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.5467 - accuracy: 0.8193 - val_loss: 0.5676 - val_accuracy: 0.8132\n",
      "Epoch 8/25\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.5389 - accuracy: 0.8200 - val_loss: 0.7273 - val_accuracy: 0.7563\n",
      "Epoch 9/25\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.5372 - accuracy: 0.8223 - val_loss: 0.5782 - val_accuracy: 0.8191\n",
      "Epoch 10/25\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.5299 - accuracy: 0.8248 - val_loss: 0.8594 - val_accuracy: 0.7337\n",
      "Epoch 11/25\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.8284 - val_loss: 0.5531 - val_accuracy: 0.8174\n",
      "Epoch 12/25\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.8317 - val_loss: 0.7250 - val_accuracy: 0.7697\n",
      "Epoch 13/25\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.8293 - val_loss: 0.6027 - val_accuracy: 0.8028\n",
      "Epoch 14/25\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.8340 - val_loss: 0.6025 - val_accuracy: 0.7986\n",
      "Epoch 15/25\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.8331 - val_loss: 0.5783 - val_accuracy: 0.8032\n",
      "Epoch 16/25\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.8399 - val_loss: 0.5791 - val_accuracy: 0.8070\n",
      "Epoch 17/25\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.8361 - val_loss: 0.5826 - val_accuracy: 0.8124\n",
      "Epoch 18/25\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.8401 - val_loss: 0.7733 - val_accuracy: 0.7412\n",
      "Epoch 19/25\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.8392 - val_loss: 0.5790 - val_accuracy: 0.8271\n",
      "Epoch 20/25\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.8435 - val_loss: 0.5256 - val_accuracy: 0.8396\n",
      "Epoch 21/25\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.4967 - accuracy: 0.8428 - val_loss: 0.5312 - val_accuracy: 0.8409\n",
      "Epoch 22/25\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.4990 - accuracy: 0.8442 - val_loss: 0.6444 - val_accuracy: 0.7772\n",
      "Epoch 23/25\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.4979 - accuracy: 0.8455 - val_loss: 0.5073 - val_accuracy: 0.8384\n",
      "Epoch 24/25\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.8464 - val_loss: 0.5235 - val_accuracy: 0.8354\n",
      "Epoch 25/25\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.8476 - val_loss: 0.5756 - val_accuracy: 0.7994\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "# If multiclass, use \"sparse_categorical_crossentropy\" as the loss function\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=25,\n",
    "                    validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5755746364593506, 0.7994137406349182]"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.58\n",
      "accuracy: 79.94%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "\n",
    "callback = [earlystop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a cross-sectional deep model using Keras (with two or more hidden layers) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(3, return_sequences=True, input_shape=[n_steps, n_inputs] ),\n",
    "    keras.layers.SimpleRNN(3, return_sequences=True),\n",
    "     keras.layers.SimpleRNN(3, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(3),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "175/175 [==============================] - 17s 78ms/step - loss: 1.0788 - accuracy: 0.5960 - val_loss: 1.4481 - val_accuracy: 0.2693\n",
      "Epoch 2/25\n",
      "175/175 [==============================] - 13s 75ms/step - loss: 0.9015 - accuracy: 0.6454 - val_loss: 0.8206 - val_accuracy: 0.6826\n",
      "Epoch 3/25\n",
      "175/175 [==============================] - 13s 74ms/step - loss: 0.8606 - accuracy: 0.6726 - val_loss: 0.7980 - val_accuracy: 0.7006\n",
      "Epoch 4/25\n",
      "175/175 [==============================] - 13s 74ms/step - loss: 0.8181 - accuracy: 0.6945 - val_loss: 0.7920 - val_accuracy: 0.7031\n",
      "Epoch 5/25\n",
      "175/175 [==============================] - 13s 75ms/step - loss: 0.8070 - accuracy: 0.7041 - val_loss: 0.8281 - val_accuracy: 0.7127\n",
      "Epoch 6/25\n",
      "175/175 [==============================] - 13s 75ms/step - loss: 0.7993 - accuracy: 0.7053 - val_loss: 0.7783 - val_accuracy: 0.7140\n",
      "Epoch 7/25\n",
      "175/175 [==============================] - 13s 74ms/step - loss: 0.7745 - accuracy: 0.7173 - val_loss: 0.7771 - val_accuracy: 0.7069\n",
      "Epoch 8/25\n",
      "175/175 [==============================] - 13s 74ms/step - loss: 0.7789 - accuracy: 0.7240 - val_loss: 0.9167 - val_accuracy: 0.6683\n",
      "Epoch 9/25\n",
      "175/175 [==============================] - 13s 75ms/step - loss: 0.7771 - accuracy: 0.7281 - val_loss: 0.8272 - val_accuracy: 0.7161\n",
      "Epoch 10/25\n",
      "175/175 [==============================] - 13s 74ms/step - loss: 0.7129 - accuracy: 0.7602 - val_loss: 1.1160 - val_accuracy: 0.5850\n",
      "Epoch 11/25\n",
      "175/175 [==============================] - 13s 75ms/step - loss: 0.7574 - accuracy: 0.7394 - val_loss: 0.7136 - val_accuracy: 0.7521\n",
      "Epoch 12/25\n",
      "175/175 [==============================] - 13s 74ms/step - loss: 0.7447 - accuracy: 0.7412 - val_loss: 1.0206 - val_accuracy: 0.6470\n",
      "Epoch 13/25\n",
      "175/175 [==============================] - 13s 74ms/step - loss: 0.7476 - accuracy: 0.7408 - val_loss: 0.7302 - val_accuracy: 0.7462\n",
      "Epoch 14/25\n",
      "175/175 [==============================] - 13s 75ms/step - loss: 0.7300 - accuracy: 0.7462 - val_loss: 0.7138 - val_accuracy: 0.7559\n",
      "Epoch 15/25\n",
      "175/175 [==============================] - 13s 75ms/step - loss: 0.7146 - accuracy: 0.7469 - val_loss: 0.7058 - val_accuracy: 0.7492\n",
      "Epoch 16/25\n",
      "175/175 [==============================] - 13s 75ms/step - loss: 0.6798 - accuracy: 0.7653 - val_loss: 0.7411 - val_accuracy: 0.7584\n",
      "Epoch 17/25\n",
      "175/175 [==============================] - 13s 75ms/step - loss: 0.6755 - accuracy: 0.7715 - val_loss: 0.6582 - val_accuracy: 0.7873\n",
      "Epoch 18/25\n",
      "175/175 [==============================] - 13s 75ms/step - loss: 0.6702 - accuracy: 0.7708 - val_loss: 0.6847 - val_accuracy: 0.7659\n",
      "Epoch 19/25\n",
      "175/175 [==============================] - 13s 75ms/step - loss: 0.6396 - accuracy: 0.7900 - val_loss: 0.7211 - val_accuracy: 0.7517\n",
      "Epoch 20/25\n",
      "175/175 [==============================] - 13s 75ms/step - loss: 0.6525 - accuracy: 0.7784 - val_loss: 0.6559 - val_accuracy: 0.7856\n",
      "Epoch 21/25\n",
      "175/175 [==============================] - 13s 74ms/step - loss: 0.6757 - accuracy: 0.7696 - val_loss: 0.6623 - val_accuracy: 0.7827\n",
      "Epoch 22/25\n",
      "175/175 [==============================] - 13s 75ms/step - loss: 0.6696 - accuracy: 0.7766 - val_loss: 0.6589 - val_accuracy: 0.7827\n",
      "Epoch 23/25\n",
      "175/175 [==============================] - 13s 74ms/step - loss: 0.6432 - accuracy: 0.7836 - val_loss: 0.6520 - val_accuracy: 0.7877\n",
      "Epoch 24/25\n",
      "175/175 [==============================] - 13s 76ms/step - loss: 0.6299 - accuracy: 0.7859 - val_loss: 0.7376 - val_accuracy: 0.7483\n",
      "Epoch 25/25\n",
      "175/175 [==============================] - 13s 75ms/step - loss: 0.6407 - accuracy: 0.7884 - val_loss: 0.6659 - val_accuracy: 0.7709\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=25,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6659407019615173, 0.7709380388259888]"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6142394542694092, 0.7923546433448792]"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(train_x, train_y, verbose=0)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.61\n",
      "accuracy: 79.24%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a sequential shallow LSTM Model (with only one LSTM layer) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.LSTM(5, activation='softmax' , input_shape=[n_steps, n_inputs])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "175/175 [==============================] - 8s 36ms/step - loss: 1.1801 - accuracy: 0.5808 - val_loss: 1.0853 - val_accuracy: 0.5590\n",
      "Epoch 2/25\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 1.0650 - accuracy: 0.5870 - val_loss: 1.0584 - val_accuracy: 0.5750\n",
      "Epoch 3/25\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 1.0535 - accuracy: 0.5867 - val_loss: 1.0732 - val_accuracy: 0.6034\n",
      "Epoch 4/25\n",
      "175/175 [==============================] - 6s 33ms/step - loss: 1.0444 - accuracy: 0.5957 - val_loss: 1.0444 - val_accuracy: 0.5670\n",
      "Epoch 5/25\n",
      "175/175 [==============================] - 6s 33ms/step - loss: 1.0391 - accuracy: 0.5917 - val_loss: 1.0675 - val_accuracy: 0.6181\n",
      "Epoch 6/25\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 1.0353 - accuracy: 0.5953 - val_loss: 1.0366 - val_accuracy: 0.5972\n",
      "Epoch 7/25\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 1.0304 - accuracy: 0.5975 - val_loss: 1.0329 - val_accuracy: 0.6177\n",
      "Epoch 8/25\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 1.0286 - accuracy: 0.6028 - val_loss: 1.0325 - val_accuracy: 0.5645\n",
      "Epoch 9/25\n",
      "175/175 [==============================] - 6s 33ms/step - loss: 1.0241 - accuracy: 0.6106 - val_loss: 1.0233 - val_accuracy: 0.6177\n",
      "Epoch 10/25\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 1.0187 - accuracy: 0.6188 - val_loss: 1.0190 - val_accuracy: 0.6235\n",
      "Epoch 11/25\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 1.0140 - accuracy: 0.6172 - val_loss: 1.0353 - val_accuracy: 0.6185\n",
      "Epoch 12/25\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 1.0106 - accuracy: 0.6233 - val_loss: 1.0054 - val_accuracy: 0.6223\n",
      "Epoch 13/25\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 1.0027 - accuracy: 0.6310 - val_loss: 0.9991 - val_accuracy: 0.6332\n",
      "Epoch 14/25\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 0.9908 - accuracy: 0.6353 - val_loss: 0.9937 - val_accuracy: 0.6361\n",
      "Epoch 15/25\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 0.9783 - accuracy: 0.6348 - val_loss: 1.0287 - val_accuracy: 0.6260\n",
      "Epoch 16/25\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 0.9680 - accuracy: 0.6355 - val_loss: 0.9545 - val_accuracy: 0.6311\n",
      "Epoch 17/25\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 0.9517 - accuracy: 0.6409 - val_loss: 0.9534 - val_accuracy: 0.6453\n",
      "Epoch 18/25\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 0.9450 - accuracy: 0.6394 - val_loss: 0.9358 - val_accuracy: 0.6424\n",
      "Epoch 19/25\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 0.9240 - accuracy: 0.6499 - val_loss: 0.9273 - val_accuracy: 0.6487\n",
      "Epoch 20/25\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 0.9149 - accuracy: 0.6583 - val_loss: 0.9272 - val_accuracy: 0.6491\n",
      "Epoch 21/25\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 0.8984 - accuracy: 0.6710 - val_loss: 0.8693 - val_accuracy: 0.6796\n",
      "Epoch 22/25\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 0.8937 - accuracy: 0.6655 - val_loss: 0.8645 - val_accuracy: 0.6826\n",
      "Epoch 23/25\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 0.8804 - accuracy: 0.6701 - val_loss: 0.8560 - val_accuracy: 0.6905\n",
      "Epoch 24/25\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 0.8890 - accuracy: 0.6579 - val_loss: 0.8773 - val_accuracy: 0.6776\n",
      "Epoch 25/25\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 0.8702 - accuracy: 0.6779 - val_loss: 0.8422 - val_accuracy: 0.6905\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=25,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8422425389289856, 0.6905360221862793]"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.84\n",
      "accuracy: 69.05%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a sequential deep LSTM Model (with only two LSTM layers) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(3, return_sequences=True, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.LSTM(3, return_sequences=False),\n",
    "    \n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "175/175 [==============================] - 19s 78ms/step - loss: 1.1574 - accuracy: 0.5958 - val_loss: 1.0793 - val_accuracy: 0.6152\n",
      "Epoch 2/25\n",
      "175/175 [==============================] - 12s 70ms/step - loss: 1.0474 - accuracy: 0.6289 - val_loss: 1.0558 - val_accuracy: 0.6248\n",
      "Epoch 3/25\n",
      "175/175 [==============================] - 12s 70ms/step - loss: 0.9961 - accuracy: 0.6441 - val_loss: 0.8941 - val_accuracy: 0.6692\n",
      "Epoch 4/25\n",
      "175/175 [==============================] - 12s 70ms/step - loss: 0.8601 - accuracy: 0.6814 - val_loss: 0.8866 - val_accuracy: 0.6792\n",
      "Epoch 5/25\n",
      "175/175 [==============================] - 12s 70ms/step - loss: 0.8092 - accuracy: 0.7109 - val_loss: 0.7964 - val_accuracy: 0.7274\n",
      "Epoch 6/25\n",
      "175/175 [==============================] - 12s 70ms/step - loss: 0.7495 - accuracy: 0.7408 - val_loss: 0.7437 - val_accuracy: 0.7638\n",
      "Epoch 7/25\n",
      "175/175 [==============================] - 12s 70ms/step - loss: 0.7084 - accuracy: 0.7687 - val_loss: 0.6837 - val_accuracy: 0.7869\n",
      "Epoch 8/25\n",
      "175/175 [==============================] - 12s 70ms/step - loss: 0.6661 - accuracy: 0.7832 - val_loss: 0.6450 - val_accuracy: 0.7902\n",
      "Epoch 9/25\n",
      "175/175 [==============================] - 12s 70ms/step - loss: 0.6451 - accuracy: 0.7904 - val_loss: 0.6260 - val_accuracy: 0.7940\n",
      "Epoch 10/25\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.6621 - accuracy: 0.7864 - val_loss: 0.6461 - val_accuracy: 0.7860\n",
      "Epoch 11/25\n",
      "175/175 [==============================] - 12s 69ms/step - loss: 0.6242 - accuracy: 0.8051 - val_loss: 0.6404 - val_accuracy: 0.7994\n",
      "Epoch 12/25\n",
      "175/175 [==============================] - 12s 69ms/step - loss: 0.6074 - accuracy: 0.8078 - val_loss: 0.6011 - val_accuracy: 0.8170\n",
      "Epoch 13/25\n",
      "175/175 [==============================] - 12s 70ms/step - loss: 0.6138 - accuracy: 0.8046 - val_loss: 0.5836 - val_accuracy: 0.8162\n",
      "Epoch 14/25\n",
      "175/175 [==============================] - 12s 71ms/step - loss: 0.6065 - accuracy: 0.8069 - val_loss: 0.6115 - val_accuracy: 0.8099\n",
      "Epoch 15/25\n",
      "175/175 [==============================] - 12s 69ms/step - loss: 0.5913 - accuracy: 0.8132 - val_loss: 0.5653 - val_accuracy: 0.8233\n",
      "Epoch 16/25\n",
      "175/175 [==============================] - 12s 70ms/step - loss: 0.5631 - accuracy: 0.8230 - val_loss: 0.5324 - val_accuracy: 0.8342\n",
      "Epoch 17/25\n",
      "175/175 [==============================] - 12s 69ms/step - loss: 0.5601 - accuracy: 0.8254 - val_loss: 0.5718 - val_accuracy: 0.8191\n",
      "Epoch 18/25\n",
      "175/175 [==============================] - 12s 69ms/step - loss: 0.5543 - accuracy: 0.8322 - val_loss: 0.6317 - val_accuracy: 0.7965\n",
      "Epoch 19/25\n",
      "175/175 [==============================] - 12s 69ms/step - loss: 0.5426 - accuracy: 0.8401 - val_loss: 0.5454 - val_accuracy: 0.8513\n",
      "Epoch 20/25\n",
      "175/175 [==============================] - 12s 69ms/step - loss: 0.5492 - accuracy: 0.8309 - val_loss: 0.5144 - val_accuracy: 0.8409\n",
      "Epoch 21/25\n",
      "175/175 [==============================] - 12s 70ms/step - loss: 0.5430 - accuracy: 0.8374 - val_loss: 0.5611 - val_accuracy: 0.8237\n",
      "Epoch 22/25\n",
      "175/175 [==============================] - 12s 70ms/step - loss: 0.5410 - accuracy: 0.8396 - val_loss: 0.4896 - val_accuracy: 0.8639\n",
      "Epoch 23/25\n",
      "175/175 [==============================] - 12s 70ms/step - loss: 0.5063 - accuracy: 0.8543 - val_loss: 0.4912 - val_accuracy: 0.8530\n",
      "Epoch 24/25\n",
      "175/175 [==============================] - 12s 70ms/step - loss: 0.5172 - accuracy: 0.8478 - val_loss: 0.5877 - val_accuracy: 0.8208\n",
      "Epoch 25/25\n",
      "175/175 [==============================] - 12s 70ms/step - loss: 0.5143 - accuracy: 0.8514 - val_loss: 0.5329 - val_accuracy: 0.8346\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=25, \n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5329044461250305, 0.8345896005630493]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.53\n",
      "accuracy: 83.46%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a sequential shallow GRU Model (with only one GRU layer) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(3, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "175/175 [==============================] - 10s 44ms/step - loss: 1.1674 - accuracy: 0.5797 - val_loss: 1.1333 - val_accuracy: 0.5800\n",
      "Epoch 2/25\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 1.1252 - accuracy: 0.5829 - val_loss: 1.1338 - val_accuracy: 0.5800\n",
      "Epoch 3/25\n",
      "175/175 [==============================] - 7s 42ms/step - loss: 1.1181 - accuracy: 0.5829 - val_loss: 1.1314 - val_accuracy: 0.5800\n",
      "Epoch 4/25\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 1.0731 - accuracy: 0.5813 - val_loss: 1.0562 - val_accuracy: 0.5616\n",
      "Epoch 5/25\n",
      "175/175 [==============================] - 7s 42ms/step - loss: 1.0334 - accuracy: 0.5937 - val_loss: 1.0498 - val_accuracy: 0.6101\n",
      "Epoch 6/25\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 1.0209 - accuracy: 0.5931 - val_loss: 1.0258 - val_accuracy: 0.6034\n",
      "Epoch 7/25\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 1.0143 - accuracy: 0.5919 - val_loss: 1.0168 - val_accuracy: 0.6147\n",
      "Epoch 8/25\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 1.0060 - accuracy: 0.6005 - val_loss: 1.0041 - val_accuracy: 0.6039\n",
      "Epoch 9/25\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.9856 - accuracy: 0.6136 - val_loss: 0.9877 - val_accuracy: 0.6068\n",
      "Epoch 10/25\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.9593 - accuracy: 0.6161 - val_loss: 0.9592 - val_accuracy: 0.6198\n",
      "Epoch 11/25\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.9310 - accuracy: 0.6246 - val_loss: 0.9389 - val_accuracy: 0.5791\n",
      "Epoch 12/25\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.9139 - accuracy: 0.6271 - val_loss: 0.9076 - val_accuracy: 0.6043\n",
      "Epoch 13/25\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.8958 - accuracy: 0.6290 - val_loss: 0.8954 - val_accuracy: 0.6327\n",
      "Epoch 14/25\n",
      "175/175 [==============================] - 7s 42ms/step - loss: 0.8886 - accuracy: 0.6360 - val_loss: 0.8971 - val_accuracy: 0.6189\n",
      "Epoch 15/25\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.8815 - accuracy: 0.6448 - val_loss: 0.8865 - val_accuracy: 0.6327\n",
      "Epoch 16/25\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.8777 - accuracy: 0.6436 - val_loss: 0.8768 - val_accuracy: 0.6533\n",
      "Epoch 17/25\n",
      "175/175 [==============================] - 7s 42ms/step - loss: 0.8741 - accuracy: 0.6739 - val_loss: 0.8776 - val_accuracy: 0.6729\n",
      "Epoch 18/25\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.8708 - accuracy: 0.6779 - val_loss: 0.8681 - val_accuracy: 0.6801\n",
      "Epoch 19/25\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.8688 - accuracy: 0.6841 - val_loss: 0.8870 - val_accuracy: 0.6863\n",
      "Epoch 20/25\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.8650 - accuracy: 0.6888 - val_loss: 0.8746 - val_accuracy: 0.6922\n",
      "Epoch 21/25\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.8590 - accuracy: 0.6936 - val_loss: 0.8598 - val_accuracy: 0.6809\n",
      "Epoch 22/25\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.8562 - accuracy: 0.6902 - val_loss: 0.8631 - val_accuracy: 0.6889\n",
      "Epoch 23/25\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.8541 - accuracy: 0.6927 - val_loss: 0.8543 - val_accuracy: 0.6893\n",
      "Epoch 24/25\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.8527 - accuracy: 0.6913 - val_loss: 0.8791 - val_accuracy: 0.6696\n",
      "Epoch 25/25\n",
      "175/175 [==============================] - 7s 40ms/step - loss: 0.8497 - accuracy: 0.6929 - val_loss: 0.8744 - val_accuracy: 0.6767\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=25,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8743905425071716, 0.6767169237136841]"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.87\n",
      "accuracy: 67.67%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a sequential deep GRU Model (with only two GRU layers) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(7, return_sequences=True, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.GRU(6),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "175/175 [==============================] - 21s 91ms/step - loss: 1.1168 - accuracy: 0.5795 - val_loss: 1.0518 - val_accuracy: 0.6101\n",
      "Epoch 2/25\n",
      "175/175 [==============================] - 14s 83ms/step - loss: 1.0246 - accuracy: 0.6010 - val_loss: 1.0172 - val_accuracy: 0.6126\n",
      "Epoch 3/25\n",
      "175/175 [==============================] - 15s 84ms/step - loss: 0.9636 - accuracy: 0.6330 - val_loss: 0.9369 - val_accuracy: 0.5992\n",
      "Epoch 4/25\n",
      "175/175 [==============================] - 15s 83ms/step - loss: 0.6948 - accuracy: 0.7627 - val_loss: 0.5587 - val_accuracy: 0.8187\n",
      "Epoch 5/25\n",
      "175/175 [==============================] - 14s 82ms/step - loss: 0.5545 - accuracy: 0.8313 - val_loss: 0.5438 - val_accuracy: 0.8333\n",
      "Epoch 6/25\n",
      "175/175 [==============================] - 15s 83ms/step - loss: 0.4931 - accuracy: 0.8518 - val_loss: 0.4810 - val_accuracy: 0.8534\n",
      "Epoch 7/25\n",
      "175/175 [==============================] - 14s 82ms/step - loss: 0.4786 - accuracy: 0.8545 - val_loss: 0.4657 - val_accuracy: 0.8585\n",
      "Epoch 8/25\n",
      "175/175 [==============================] - 14s 83ms/step - loss: 0.4512 - accuracy: 0.8650 - val_loss: 0.4549 - val_accuracy: 0.8551\n",
      "Epoch 9/25\n",
      "175/175 [==============================] - 14s 82ms/step - loss: 0.4431 - accuracy: 0.8656 - val_loss: 0.4604 - val_accuracy: 0.8668\n",
      "Epoch 10/25\n",
      "175/175 [==============================] - 14s 83ms/step - loss: 0.4703 - accuracy: 0.8589 - val_loss: 0.4400 - val_accuracy: 0.8714\n",
      "Epoch 11/25\n",
      "175/175 [==============================] - 14s 83ms/step - loss: 0.4274 - accuracy: 0.8724 - val_loss: 0.4335 - val_accuracy: 0.8689\n",
      "Epoch 12/25\n",
      "175/175 [==============================] - 14s 82ms/step - loss: 0.4203 - accuracy: 0.8728 - val_loss: 0.4241 - val_accuracy: 0.8773\n",
      "Epoch 13/25\n",
      "175/175 [==============================] - 15s 83ms/step - loss: 0.4210 - accuracy: 0.8769 - val_loss: 0.4311 - val_accuracy: 0.8702\n",
      "Epoch 14/25\n",
      "175/175 [==============================] - 15s 84ms/step - loss: 0.4066 - accuracy: 0.8850 - val_loss: 0.4030 - val_accuracy: 0.8844\n",
      "Epoch 15/25\n",
      "175/175 [==============================] - 15s 83ms/step - loss: 0.3958 - accuracy: 0.8878 - val_loss: 0.4108 - val_accuracy: 0.8777\n",
      "Epoch 16/25\n",
      "175/175 [==============================] - 15s 83ms/step - loss: 0.3940 - accuracy: 0.8871 - val_loss: 0.3804 - val_accuracy: 0.8924\n",
      "Epoch 17/25\n",
      "175/175 [==============================] - 14s 83ms/step - loss: 0.3851 - accuracy: 0.8900 - val_loss: 0.3888 - val_accuracy: 0.8899\n",
      "Epoch 18/25\n",
      "175/175 [==============================] - 14s 83ms/step - loss: 0.3708 - accuracy: 0.8957 - val_loss: 0.3952 - val_accuracy: 0.8836\n",
      "Epoch 19/25\n",
      "175/175 [==============================] - 15s 83ms/step - loss: 0.3877 - accuracy: 0.8898 - val_loss: 0.3782 - val_accuracy: 0.8924\n",
      "Epoch 20/25\n",
      "175/175 [==============================] - 15s 84ms/step - loss: 0.3697 - accuracy: 0.8959 - val_loss: 0.3993 - val_accuracy: 0.8773\n",
      "Epoch 21/25\n",
      "175/175 [==============================] - 15s 83ms/step - loss: 0.3559 - accuracy: 0.9004 - val_loss: 0.3715 - val_accuracy: 0.8907\n",
      "Epoch 22/25\n",
      "175/175 [==============================] - 15s 83ms/step - loss: 0.3455 - accuracy: 0.9022 - val_loss: 0.3782 - val_accuracy: 0.8907\n",
      "Epoch 23/25\n",
      "175/175 [==============================] - 15s 83ms/step - loss: 0.3664 - accuracy: 0.8918 - val_loss: 0.3804 - val_accuracy: 0.8991\n",
      "Epoch 24/25\n",
      "175/175 [==============================] - 14s 82ms/step - loss: 0.3437 - accuracy: 0.9022 - val_loss: 0.3389 - val_accuracy: 0.9049\n",
      "Epoch 25/25\n",
      "175/175 [==============================] - 15s 83ms/step - loss: 0.3287 - accuracy: 0.9061 - val_loss: 0.3491 - val_accuracy: 0.9037\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=25,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.34906959533691406, 0.9036850929260254]"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3154158890247345, 0.9109835028648376]"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(train_x, train_y, verbose=0)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.32\n",
      "accuracy: 91.10%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List the test values of each model you built (0.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-sectional shallow model using Keras (with only one hidden layer)\n",
    "\n",
    "loss: 0.58\n",
    "accuracy: 79.94%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-sectional deep model using Keras (with two or more hidden layers):\n",
    "\n",
    "loss: 0.61\n",
    "accuracy: 79.24%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential shallow model LSTM model ( with only one LSTM layer) :\n",
    "\n",
    "loss: 0.84\n",
    "accuracy: 69.05%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential shallow model LSTM model ( with only two LSTM layer) :\n",
    "\n",
    "loss: 0.53\n",
    "accuracy: 83.46%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shallow model using GRU model (with only one GRU layer):\n",
    "    \n",
    "loss: 0.87\n",
    "accuracy: 67.67%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shallow model using GRU model (with only two GRU layer) :\n",
    "\n",
    "loss: 0.32\n",
    "accuracy: 91.10%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which model performs the best and why? (0.5 points) \n",
    "## How does it compare to baseline? (0.5 points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running all the models, shallow GRU model (with only two GRU models) has the highest accuracy with 91.10%. It is my best model out of all the models.  The baseline is 58.20%, my model has highest prediction above the baseline.\n",
    "\n",
    "This model achieved highest accuracy because I have used two hidden layer with change in nuerons. I also changed activation model to softmax, Adam as an optimizer and Sparse-categorical-crossentropy has loss funtion for my model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
